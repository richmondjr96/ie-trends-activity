{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "2.7.12",
      "pygments_lexer": "ipython2",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    },
    "colab": {
      "name": "plot_cv_diabetes.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzjz6ffmOlWO"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wHht831OlYH"
      },
      "source": [
        "\n",
        "# Cross-validation on diabetes Dataset Exercise\n",
        "\n",
        "\n",
        "A tutorial exercise which uses cross-validation with linear models.\n",
        "\n",
        "This exercise is used in the :ref:`cv_estimators_tut` part of the\n",
        ":ref:`model_selection_tut` section of the :ref:`stat_learn_tut_index`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jeg2IZc_OlYM"
      },
      "source": [
        "from __future__ import print_function\n",
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "diabetes = datasets.load_diabetes()\n",
        "X = diabetes.data[:150]\n",
        "y = diabetes.target[:150]\n",
        "\n",
        "lasso = Lasso(random_state=0)\n",
        "alphas = np.logspace(-4, -0.5, 30)\n",
        "\n",
        "scores = list()\n",
        "scores_std = list()\n",
        "\n",
        "n_folds = 3\n",
        "\n",
        "for alpha in alphas:\n",
        "    lasso.alpha = alpha\n",
        "    this_scores = cross_val_score(lasso, X, y, cv=n_folds, n_jobs=1)\n",
        "    scores.append(np.mean(this_scores))\n",
        "    scores_std.append(np.std(this_scores))\n",
        "\n",
        "scores, scores_std = np.array(scores), np.array(scores_std)\n",
        "\n",
        "plt.figure().set_size_inches(8, 6)\n",
        "plt.semilogx(alphas, scores)\n",
        "\n",
        "# plot error lines showing +/- std. errors of the scores\n",
        "std_error = scores_std / np.sqrt(n_folds)\n",
        "\n",
        "plt.semilogx(alphas, scores + std_error, 'b--')\n",
        "plt.semilogx(alphas, scores - std_error, 'b--')\n",
        "\n",
        "# alpha=0.2 controls the translucency of the fill color\n",
        "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
        "\n",
        "plt.ylabel('CV score +/- std error')\n",
        "plt.xlabel('alpha')\n",
        "plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
        "plt.xlim([alphas[0], alphas[-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjdAePsOOlYa"
      },
      "source": [
        "Bonus: how much can you trust the selection of alpha?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvDG9rQJOlYd"
      },
      "source": [
        "# To answer this question we use the LassoCV object that sets its alpha\n",
        "# parameter automatically from the data by internal cross-validation (i.e. it\n",
        "# performs cross-validation on the training data it receives).\n",
        "# We use external cross-validation to see how much the automatically obtained\n",
        "# alphas differ across different cross-validation folds.\n",
        "lasso_cv = LassoCV(alphas=alphas, random_state=0)\n",
        "k_fold = KFold(3)\n",
        "\n",
        "print(\"Answer to the bonus question:\",\n",
        "      \"how much can you trust the selection of alpha?\")\n",
        "print()\n",
        "print(\"Alpha parameters maximising the generalization score on different\")\n",
        "print(\"subsets of the data:\")\n",
        "for k, (train, test) in enumerate(k_fold.split(X, y)):\n",
        "    lasso_cv.fit(X[train], y[train])\n",
        "    print(\"[fold {0}] alpha: {1:.5f}, score: {2:.5f}\".\n",
        "          format(k, lasso_cv.alpha_, lasso_cv.score(X[test], y[test])))\n",
        "print()\n",
        "print(\"Answer: Not very much since we obtained different alphas for different\")\n",
        "print(\"subsets of the data and moreover, the scores for these alphas differ\")\n",
        "print(\"quite substantially.\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}